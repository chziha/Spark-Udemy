{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's see an example of how to run a logistic regression with Python and Spark! This is documentation example, we will quickly run through this and then show a more realistic example, afterwards, you will have another consulting project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/czh/spark-2.4.6-bin-hadoop2.7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('logregdoc').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+----------+\n",
      "|probability                                |prediction|\n",
      "+-------------------------------------------+----------+\n",
      "|[0.9999999976135945,2.3864054543471998E-9] |0.0       |\n",
      "|[1.4132155511105642E-9,0.9999999985867845] |1.0       |\n",
      "|[1.2580486512697989E-12,0.9999999999987419]|1.0       |\n",
      "|[6.427105091703036E-9,0.9999999935728949]  |1.0       |\n",
      "|[1.2715720920060412E-9,0.9999999987284278] |1.0       |\n",
      "|[0.9999999976067364,2.393263547463311E-9]  |0.0       |\n",
      "|[1.4710981469558102E-9,0.9999999985289019] |1.0       |\n",
      "|[3.088501681026319E-9,0.9999999969114983]  |1.0       |\n",
      "|[0.9999999957267036,4.273296361841363E-9]  |0.0       |\n",
      "|[0.9999999999448097,5.519035886749981E-11] |0.0       |\n",
      "|[2.5681887277651024E-11,0.9999999999743181]|1.0       |\n",
      "|[0.9999999999962461,3.753800775785978E-12] |0.0       |\n",
      "|[0.9999999999939617,6.038255127600314E-12] |0.0       |\n",
      "|[2.5311068452957554E-9,0.9999999974688931] |1.0       |\n",
      "|[0.9999999992612372,7.387628925283089E-10] |0.0       |\n",
      "|[1.2980601879094132E-10,0.9999999998701941]|1.0       |\n",
      "|[0.9999999995423565,4.576434539331673E-10] |0.0       |\n",
      "|[0.9999999999999873,1.275671720228916E-14] |0.0       |\n",
      "|[1.2240911561650543E-9,0.999999998775909]  |1.0       |\n",
      "|[2.182504754003321E-10,0.9999999997817495] |1.0       |\n",
      "+-------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingSummary.predictions.select('probability', 'prediction').show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = training.randomSplit([0.3, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.BinaryLogisticRegressionSummary at 0x7f3462bd32e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = lrModel.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[27.2697742627702...|[0.99999999999856...|       0.0|\n",
      "|  0.0|(692,[121,122,123...|[22.4609704788300...|[0.99999999982407...|       0.0|\n",
      "|  0.0|(692,[122,123,124...|[18.6050132640227...|[0.99999999168340...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[31.9491790434436...|[0.99999999999998...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[31.7577501460002...|[0.99999999999998...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[37.1587404143751...|[1.0,7.2805482360...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[30.1092845501855...|[0.99999999999991...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[29.6147429436880...|[0.99999999999986...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[17.9280323186061...|[0.99999998363355...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[22.7640878047271...|[0.99999999987007...|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[13.7579291634415...|[0.99999894072963...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[20.2281842381022...|[0.99999999835936...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[20.9945400808944...|[0.99999999923759...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[23.1753561648756...|[0.99999999991388...|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[18.5526995861606...|[0.99999999123675...|       0.0|\n",
      "|  0.0|(692,[129,130,131...|[14.2618168175373...|[0.99999936001266...|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[21.9977201446139...|[0.99999999972041...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[28.1531148592461...|[0.99999999999940...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[15.6124164237371...|[0.99999983418889...|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[27.3341801231122...|[0.99999999999865...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = predictionAndLabels.predictions.select('label','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluators\n",
    "\n",
    "Evaluators will be a very important part of our pipline when working with Machine Learning, let's see some basics for Logistic Regression, useful links:\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiclass\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',\n",
    "                                             metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = evaluator.evaluate(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay let's move on see some more examples!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
